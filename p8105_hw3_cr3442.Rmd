---
title: "p8105_hw3_cr3442"
author: "Cheng Rao"
date: "2024-10-15"
output: github_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

First of all, let me explain why I did not submit multiple versions of the assignment and did not reflect my modification process. It is like this. I had completed part of my assignment before this week, but did not commit or push. Last Saturday, my original computer broke down. I tried to fix the computer during the weekend but failed. For this reason, I used my classmate's computer to complete this week's homework, so I did not submit the previous modification process (because I can't use icloud). And I feel that I can't submit my code through the push method that comes with R studio, but need to submit it by manually adding it on github. I am very sorry for the trouble caused to you in correcting your homework.

# Problem 1

First, we use the code on the website to import the data, which includes the IDs of all weather stations in New York State and the data in them.

```{r pull_data, echo=FALSE, results="hide", message=FALSE, warning=FALSE}

library(dplyr)
library(rnoaa)

# Get a list of all NY station IDs
stations <- ghcnd_stations()
nystationids <-  stations %>% 
  filter(state == "NY") %>% 
  distinct(id)

# Pull the desired weather data for all of these stations
nydat <- meteo_pull_monitors(nystationids$id, 
                             date_min = "1981-01-01", 
                             date_max = "2010-12-31", 
                             var = c("PRCP", "SNOW", "SNWD", "TMAX", "TMIN"))

# Save the resulting data
save(nystationids, nydat, file = "nynoaadat.RData")

```

Then we load the data, describe the size and structure of the dataset, and find out the missing values.
 
```{r load_1}

load("nynoaadat.RData")

nydat %>% 
  glimpse()

dim(nydat)

# Check the number of missing values
nydat %>% 
  summarise(across(everything(), ~sum(is.na(.))))

```

We then create separate "year", "month", and "day" variables. We make sure the temperature, precipitation, and snowfall values are in reasonable units, and finally find the most common snowfall values.

```{r temperature_1}
library(lubridate)

nydat <- nydat %>%
  mutate(
    year = year(date),
    month = month(date),
    day = day(date),
    tmax = tmax / 10,    
    tmin = tmin / 10   # Convert to Celsius
  )

# Find the most common snowfall values
nydat %>%
  count(snow) %>%
  arrange(desc(n))
```
Next we will plot the average maximum temperature for each weather station in January and July of each year.

```{r plot_temperature_1}
library(ggplot2)

# Average maximum temperature
avg_temp_jan_jul <- nydat %>%
  filter(month %in% c(1, 7)) %>%
  group_by(id, year, month) %>%
  summarise(avg_tmax = mean(tmax, na.rm = TRUE)) %>%
  ungroup()

# Draw a two-panel plot

avg_temp_jan_jul_clean <- avg_temp_jan_jul %>%
  filter(id %in% unique(id)[1:10]) 

ggplot(avg_temp_jan_jul_clean, aes(x = year, y = avg_tmax, color = id)) +
  geom_line() +
  facet_wrap(~month, ncol = 1, labeller = labeller(month = c(`1` = "January", `7` = "July"))) +
  labs(
    title = "Average maximum temperatures in January and July for each weather station",
    x = "Year",
    y = "Average maximum temperature (°C)"
  ) +
  theme_minimal()



```
Then We plotted a two-panel graph of Tmax vs. Tmin and snowfall distribution.

```{r }
#  T max vs T min
ggplot(nydat, aes(x = tmin, y = tmax)) +
  geom_hex(bins = 50) +
  labs(
    title = "Tmax vs Tmin",
    x = "T min (°C)",
    y = "T max (°C)"
  ) +
  theme_minimal()

# Distribution of snowfall values greater than 0 and less than 100

snowfall_distribution <- nydat %>%
  filter(snow > 0, snow < 100) %>%
  group_by(year)

ggplot(snowfall_distribution, aes(x = snow)) +
  geom_histogram(binwidth = 5, fill = "blue", alpha = 0.7) +
  facet_wrap(~year) +
  labs(
    title = "Distribution of snowfall values (greater than 0 and less than 100)",
    x = "Snowfall (mm)",
    y = "frequency"
  ) +
  theme_minimal()

```

# ANSWER

1.Description:

`id`: Weather station ID

`date`: Date of observation

`prcp`: Precipitation (tenths of mm)

`snow`: Snowfall (mm)

`snwd`: Snow depth (mm)

`tmax`: Maximum temperature (tenths of degrees C)

`tmin`: Minimum temperature (tenths of degrees C)

2.In data cleaning, we did the following:

Creating year, month, and day variables: We used the mutate() function to extract the year, month, and day from the date variable. 

Unit conversion: We converted tmax and tmin from 1/10 degrees Celsius to degrees Celsius.

The most common snowfall value: We counted the frequency of snowfall using count(snow) and found that 0 is the most common value. This may be because there is no snowfall in most cases, especially in summer and autumn.

3.I did not observe any data about the average maximum temperature of each weather station in January and July each year. I only had the names of the weather stations. Even if I took the data of several weather stations, I did not get any data.

4.From the figure, we can see that there is an obvious positive correlation between tmax and tmin, which is manifested by the fact that most of the data points are distributed along a positive slope. This means that when the minimum temperature is higher, the maximum temperature is usually also higher.

Many years have snowfall amounts concentrated in a smaller range (0-50 mm), meaning that most observed snowfall events are light to moderate.
However, some years have a histogram with higher snowfall amounts (e.g., 50-100 mm), which may mean that more severe snowfall events occurred in these years.


# Problem 2

```{r}
library(tidyverse)
library(readr)
```

To solve this problem, first let us load the two required datasets, and check them to make sure they are OK.

```{r load_2}

getwd()
demographics <- read_csv("/Users/raocheng/Desktop/p8105_hw3_cr3442/data/demographics.csv")
accelerometer <- read_csv("/Users/raocheng/Desktop/p8105_hw3_cr3442/data/accelerometer.csv")

# Preview the first few rows of each dataset
head(demographics)
head(accelerometer)
```

Because the demographics data does not meet the requirements for subsequent operations, we perform some cleaning.

```{r clean_2}

# Omit the first four rows of data because of the column of age
cleaned_demographics <- read_csv("/Users/raocheng/Desktop/p8105_hw3_cr3442/data/demographics.csv", skip = 4)

head(cleaned_demographics)
str(cleaned_demographics)

```

Next, it is time to merge these data.

```{r merge_2}

merged_data <- inner_join(cleaned_demographics, accelerometer, by = "SEQN")

# Check the merged data
head(merged_data)

```
Next, let’s summarize the data.

```{r summary_2}

# Count the number of people by education level and gender
summary_table <- merged_data %>%
  group_by(education, sex) %>%
  summarize(count = n(), .groups = 'drop')


print(summary_table)
```

Then visualize the data.

```{r visualize_2}

# Draw the age distribution graph with clear gender labels
ggplot(merged_data, aes(x = age, fill = as.factor(sex))) +
  geom_histogram(bins = 30, alpha = 0.6, position = "identity") +
  facet_wrap(~ education) +
  labs(title = "Age Distribution by Gender and Education Level",
       x = "Age", y = "Count", fill = "Gender") +
  scale_fill_manual(values = c("1" = "blue", "2" = "red"),
                    labels = c("Male", "Female")) +
  theme_minimal()

```

Analysis:

Educational category 1: has a high distribution in both younger (around 20 years old) and older (70-80 years old) groups, with a relatively balanced gender distribution, but slightly more women in some specific age groups (such as around 50 years old).

Educational category 2: The age distribution at this education level is relatively scattered, and the proportion of men and women in different age groups is not much different. This category is also highly distributed in the older age group (70-80 years old).

Educational category 3: has a significantly higher distribution in the younger population (20-30 years old), and there are more men than women. There are also more participants in the 60-70 age group. This may indicate that this education level is more common in the younger group.

Overall, the distribution of men and women at different education levels is roughly the same, but there are some subtle differences. For example, in education category 1, there are significantly more women than men around 50 years old, while there are more men in education category 3 in the 20-30 age group.

There seems to be some correlation between education level and age distribution, which may be due to individuals in certain age groups being more inclined to certain education levels.



The accelerometer data contains minute-by-minute activity data for 24 hours, and we need to summarize the activity for each participant.

```{r total_act_2}

# Summarize the total activity for each participant
total_activity <- merged_data %>%
  rowwise() %>%
  mutate(total_activity = sum(c_across(starts_with("MIMS")), na.rm = TRUE)) %>%
  ungroup()


```

Then we will plot a scatter plot of each participant's total activity versus age, distinguishing between gender and education level.

```{r ggplot_2}

# Plot the relationship between total activity and age
ggplot(total_activity, aes(x = age, y = total_activity, color = as.factor(sex))) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "loess", se = FALSE) +
  facet_wrap(~ education) +
  labs(title = "Total Activity vs Age by Gender and Education Level",
       x = "Age", y = "Total Activity", color = "Gender") +
  scale_color_manual(values = c("1" = "blue", "2" = "red"), labels = c("Male", "Female")) +
  theme_minimal()

```

Analysis: Gender and education differences do not appear to be significant.

Finally, create a three-panel plot showing the 24-hour activity time trajectory for each education level, color-coded by gender.

```{r covert_2}

# Convert activity data for each minute within 24 hours to long format
activity_long <- merged_data %>%
  pivot_longer(cols = starts_with("min"), names_to = "minute", values_to = "activity") %>%
  mutate(minute = as.numeric(gsub("min", "", minute)))

# Draw 24-hour activity trajectory
ggplot(activity_long, aes(x = minute, y = activity, color = sex)) +
  geom_smooth(se = FALSE) +
  facet_wrap(~ education) +
  labs(title = "24-hour activity time trajectory by education level",
       x = "Minutes of the Day", y = "Activity Level", color = "gender") +
  theme_minimal()

```

Analysis: 
The chart shows the age distribution of men (red) and women (blue) at different education levels.

In the case of education level 1, the age distribution is relatively wide, with a relatively balanced distribution from 20 to 80 years old. The distribution of men and women is similar in all age groups, but there are more women in the higher age groups (70-80 years old).

In the case of education level 2, the age distribution is more dispersed, covering multiple age groups, and the ratio between men and women is not much different in most age groups.

In the case of education level 3, there is a clear peak in the age group of 20-30 years old, especially the higher proportion of men, indicating that young people are more in this education level.

The number of participants gradually decreases with age, but it is worth noting that there is another smaller peak in the age group of 60-70 years old.

# Problem 3

```{r}
library(tidyverse)
library(lubridate)
```

To solve this problem, first let us load the four required datasets, and check them to make sure they are OK.

```{r load_3}

setwd("/Users/raocheng/Desktop/p8105_hw3_cr3442")
getwd()

Jan_2020_Citi <- read_csv("/Users/raocheng/Desktop/p8105_hw3_cr3442/data/Jan_2020_Citi.csv")
Jan_2024_Citi <- read_csv("/Users/raocheng/Desktop/p8105_hw3_cr3442/data/Jan_2024_Citi.csv")
July_2020_Citi <- read_csv("/Users/raocheng/Desktop/p8105_hw3_cr3442/data/July_2020_Citi.csv")
July_2024_Citi <- read_csv("/Users/raocheng/Desktop/p8105_hw3_cr3442/data/July_2024_Citi.csv")

# Preview the first few rows of each dataset
head(Jan_2020_Citi)
head(Jan_2024_Citi)
head(July_2020_Citi)
head(July_2024_Citi)
```

Then merge them.

```{r merge_3}
# Merge all datasets
citi_bike_data <- bind_rows(
  Jan_2020_Citi %>% mutate(year = 2020, month = "January"),
  July_2020_Citi %>% mutate(year = 2020, month = "July"),
  Jan_2024_Citi %>% mutate(year = 2024, month = "January"),
  July_2024_Citi %>% mutate(year = 2024, month = "July")
)

head(citi_bike_data)
```

Next, we need to clean and organize the data.

```{r clean_3}
# Clean and organize data
citi_bike_data_cleaned <- citi_bike_data %>%
  mutate(day_of_week = weekdays,  # Use existing weekday column
         duration_minutes = duration,  
         member_casual = ifelse(member_casual == "member", "Member", "Casual")) %>%
  drop_na()  

# check the cleaned data
head(citi_bike_data_cleaned)
```

Generate a summary table showing the total number of rides for members and non-members per month of each year.

```{r summary_3}

ride_summary <- citi_bike_data_cleaned %>%
  group_by(year, month, member_casual) %>%
  summarize(total_rides = n(), .groups = 'drop')

# Generate tabular output
ride_summary_table <- ride_summary %>%
  pivot_wider(names_from = member_casual, values_from = total_rides, values_fill = 0)

print(ride_summary_table)
```

Find the top 5 most popular starting stations for July 2024 and show the number of rides from each station.

```{r station_3}
# Filter out data from July 2024
july_2024_data <- citi_bike_data_cleaned %>%
  filter(year == 2024, month == "July")

# Find the most popular starting stations
top_start_stations <- july_2024_data %>%
  group_by(start_station_name) %>%
  summarize(total_rides = n(), .groups = 'drop') %>%
  arrange(desc(total_rides)) %>%
  slice_head(n = 5)

print(top_start_stations)
```

Next, plot a graph to see how the median duration of a ride changes by week, month, and year.

```{r median_3}
# Calculate the median riding time for each group
median_ride_duration <- citi_bike_data_cleaned %>%
  group_by(year, month, day_of_week) %>%
  summarize(median_duration = median(duration_minutes), .groups = 'drop')

# Draw a chart
ggplot(median_ride_duration, aes(x = day_of_week, y = median_duration, fill = month)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~ year) +
  labs(title = "Median cycling duration by week, month, and year",
       x = "week", y = "Median riding time (minutes)", fill = "month") +
  theme_minimal()
```

Analysis:
For 2020:
July rides were significantly longer than January, especially on weekends (Saturday and Sunday). This may reflect the increase in cycling in the summer months (July), when cyclists may choose to go outdoors more often. July rides peaked from Friday to Sunday, especially on Saturday and Sunday, where the median ride time exceeded 15 minutes, indicating that more people may use their weekends for longer rides. January rides were relatively short and less variable, indicating that the cold weather kept people from going out to ride, especially in 2020.
For 2024:
Compared to 2020, the overall ride time in 2024 was lower. Both January and July had relatively low peak ride times. However, the difference between January and July was not as significant in 2024 as in 2020. Although July ride time was still slightly higher than January, the difference between the two was smaller. Moreover, in 2024, the ride time from Friday to Sunday tended to be stable and decreased compared to 2020.


Finally, Let us draw a chart to show the impact of month, member status and vehicle type on the distribution of riding time in the 2024 data.

```{r distribution_3} 
# Filter data of 2024
data_2024 <- citi_bike_data_cleaned %>%
  filter(year == 2024)

# Plotting the distribution of riding time
ggplot(data_2024, aes(x = duration_minutes, fill = interaction(member_casual, rideable_type))) +
  geom_density(alpha = 0.6) +
  facet_wrap(~ month) +
  labs(title = "Distribution of riding time in 2024 (by month, membership status and vehicle type)",
       x = "Cycling time (minutes)", y = "density", fill = "membership status and vehicle type") +
  theme_minimal() +
  xlim(0, 240) 
```

Analysis:

Most of the rides are short, concentrated between 0 and 50 minutes, while longer rides (over 100 minutes) are very rare. This right-skewed distribution pattern is consistent in two months (January and July), with a clear peak, showing that most rides are concentrated in the shorter range.

The distribution pattern of classic bikes and electric bikes is similar. Although the specific differences are not big, in general, the riding time of electric bikes (especially members) is slightly longer. This may be because electric bikes are more labor-saving. If I were in the same situation, I would also prefer electric bikes.

Non-members ride slightly longer than members, which may be related to the fact that non-members tend to use rental services for longer sightseeing activities, while members may mainly use them for short-distance commuting, and non-members need to ride for a long time to make their investment back. The use of electric bicycles is more obvious among members, especially in shorter rides, which may be due to the fact that electric bicycles are more efficient in daily commuting.
